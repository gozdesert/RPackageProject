---
title: "FPCA with R-package fpcaCor"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Getting started with R-package fpcaCor}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(fpcaCor)
```

## Overview
This is a brief introduction to the package **fpcaCor**. For a general overview on functional data analysis (FDA), see (Ramsey and Silverman, 2005). Specifically, we work on functional principal component analysis (FPCA) for dimension reduction of functional data. For more details, readers can look at (@Yao:2003hd; @Goldsmith:2012ie; and @Xiao:2015jw). 

Let $X_i(t)$ be the measurement for subject $i,$ where $i = 1, 2, \dots, n$ at time $t, \ t = 1,2 \dots, T$. By using the basic idea of FPCA based on the truncation of Karhunen-Loe've (KL) decomposition as 

\begin{equation}
X_i(t) = \mu(t) + \sum_{j= 1}^r \xi_{ij}\phi_j(t) + \varepsilon_i(t),
\end{equation} 

where $\mu(t)$ is the overall mean, $\xi_{ij}$ are subject-specific scores, $\phi_j(t)$ are eigenfunctions of underlying covariance operator $K(\cdot, \cdot)$, $r$ is the truncation level and $\varepsilon_i(t)$ are iid error terms. 

## Copula FPCA
Instead of working with observed $X_i(t)$, we want to focus on a corresponding latent Gaussian $Z_i(t)$. We will apply KL decomposition to *latent* Gaussian $Z_i(t)$ rather than the *observed * $X_i(t)$. Then we get 

\begin{equation}
Z_i(t) = \mu(t) + \sum_{j= 1}^r \xi_{ij}\phi_j(t) + \varepsilon_i(t).
\end{equation} 

To get $X_i(t)$ back from $Z_i(t)$,  we use a strictly monotone transformation $f_t$ so that $f_t(X_i(t)) = Z_i(t)$ for continuous $X_i(t)$. 

For the noncontinuous case, we will use corresponding latent models from @Yoon:2020hc. See the paper (@Yoon:2020hc) for more details. 

## R project implementation
### Getting Started
First, we will generate variables with the same types, which all are continuous, using sample size $n = 30$ which will be our toy examples. To generate our toy example we will use the function `gen_data` from the R package `latentcor`. Here the number of types is 20.
```{r}
library(latentcor)
Mydata.list = gen_data(n = 30, types = rep("con", 20))
```
The function `gen_data` gives two outputs (See \code{\link[latentcor]{gen_data}}). We only need the generated data matrix X.
```{r}
X = Mydata.list$X 
head(X, n = 10)
```

We obtained a matrix X with 30 many rows (sample size) and 20 many columns (number of variables). All the variables have the sample type (continuous). 

## FPCA in R using fpcaCor

Now we can use the function `fpcaCor` to get eigen-functions for obtained data (matrix X). The function `fpcaCor` follows several steps to extract eigen-functions. First, we get the estimated latent correlation matrix $\hat K$ which can be also obtained by using the function `latentcor`. Then we use the "B-spline basis functions" to smooth the correlation matrix $\hat K$. After we obtain the smoothed correlation matrix $\tilde K$, we can extract the eigen-function for given the proportion of variance explained (pve) or for given number of principal components (npc) if it is supplied.

```{r}
outputs = fpcaCor(X, pve = 0.95)  
```

Here we only want the proportion of variance explained is %95. Since we did not supply `npc`, it is obtained by using `pve` in the function `fpcaCor`.
 
```{r}
NPC = outputs$npc
print(NPC)
```


 



### Examples
######Here we can (maybe) also talk about the gaussian_copula_cor function and give an example 

## 

# References

---
title: "Getting started with R-package fpcaCor"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Getting started with R-package fpcaCor}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(fpcaCor)
```

## Overview
This is a brief introduction to the package **fpcaCor**. For a general overview on functional data analysis (FDA), see (Ramsey and Silverman, 2005). Specifically, we work on functional principal component analysis (FPCA) for dimension reduction of functional data. For more details, readers can look at (@Yao:2003hd; @Goldsmith:2012ie; and @Xiao:2015jw). 

Let $X_i(t)$ be the measurement for subject $i,$ where $i = 1, 2, \dots, n$ at time $t, \ t = 1,2 \dots, T$. By using the basic idea of FPCA based on the truncation of Karhunen-Loe've (KL) decomposition as 

\begin{equation}
X_i(t) = \mu(t) + \sum_{j= 1}^r \xi_{ij}\phi_j(t) + \varepsilon_i(t),
\end{equation} 

where $\mu(t)$ is the overall mean, $\xi_{ij}$ are subject-specific scores, $\phi_j(t)$ are eigenfunctions of underlying covariance operator $K(\cdot, \cdot)$, $r$ is the truncation level and $\varepsilon_i(t)$ are iid error terms. 

## Copula FPCA
Instead of working with observed $X_i(t)$, we want to focus on a corresponding latent Gaussian $Z_i(t)$. We will apply KL decomposition to *latent* Gaussian $Z_i(t)$ rather than the *observed * $X_i(t)$. Then we get 

\begin{equation}
Z_i(t) = \mu(t) + \sum_{j= 1}^r \xi_{ij}\phi_j(t) + \varepsilon_i(t).
\end{equation} 

To get $X_i(t)$ back from $Z_i(t)$,  we use a strictly monotone transformation $f_t$ so that $f_t(X_i(t)) = Z_i(t)$ for continuous $X_i(t)$. 

For the noncontinuous case, we will use corresponding latent models from @Yoon:2020hc. See the paper (@Yoon:2020hc) for more details. 

## R project implementation
### Getting Started
First, we will generate variables with the same types, which all are continuous, using sample size $n = 100$ which will be our toy examples. To generate our toy example we will use the function `gen_data` from the R package `latentcor`. Here the number of types is 50.
```{r}
library(latentcor)
Mydata.list = gen_data(n = 100, types = rep("con", 50), showplot = TRUE)
X = Mydata.list$X   #this is data we want to use.
```

We obtained a matrix X with 100 many rows (sample size) and 50 many columns (number of variables). All the variables have the sample type (continuous). Now we can use our main function `fpca.cor` to do functional principal component analysis.
## FPCA in R using fpcaCor

### Examples
######Here we can (maybe) also talk about the gaussian_copula_cor function and give an example 

## 

# References
